# Первая версия ТЗ

Я хочу построить ИИ ассистента, который специализируется на глубоком самоанализе и выявлении ваших истинных желаний, целей и приоритетов в жизни. Он глубоко интегрирован в понимание моей личности через анализ моих рассказов о себе, через анализ импортированных файлов с разговорами с другими ИИ и через анализ нашего с ним общения. Главная задача такого ассистента — помогать мне разбираться с вопросами вида "чего же я сейчас хочу в текущий момент жизни" или "какой именно проект я сейчас хочу сделать", но не ограничиваясь ими; как именно он будет это делать - через прямые ответы, через Сократический диалог или как-то ещё - я не знаю, выбор правильной стратегии общения я делегирую на ИИ ассистента.

Этот ИИ должен обладать многоуровневой архитектурой памяти, учитывать биографический, эмоциональный и поведенческий контекст, уметь распознавать неявные намерения и эмоциональное состояние. Он должен быть нейтральным, аналитическим партнером. 

Очень важно: он должен учитывать специфику моего характера. Мои предпочтения, желания и цели в жизни меняются очень часто - ИИ ассистент должен это внимательно учитывать и уметь с этим справляться. Со своей стороны я могу проставлять даты к  рассказам о себе и к общениям с другими ИИ, чтобы облегчить задачу этому ИИ ассистенту.

Задача — создать сервис или минисервис (например, чатбот или приложение), включающий в себя:

- Продвинутую структуру вопрос-ответ
- Самостоятельный выбор стратегии общегия: прямой ответ или Сократический диалог для самокопания
- Механизмы хранения и анализа истории взаимодействий и изменяющихся приоритетов
- Контекстно-зависимый анализ эмоционального состояния и паттернов поведения
- Пошаговую методику ведения глубоких рефлексивных сессий с пользователем

Этот сервис должен быть реализован с возможностью масштабирования (например, интеграция с мессенджерами, личными заметками, календарями) и поддерживать трансформацию диалога в инсайты, а не просто предоставлять конечные решения.

Ассистент должен анализировать не просто текст моих ответов, но и:
 • Эмоциональный подтекст — грусть, фрустрацию, возбуждение, страх
 • Временной контекст — понимать, что люди под стрессом принимают другие решения, чем в спокойном состоянии

Также ассистент должен быть проактивным. Он должен уметь вовремя сказать что-то вроде "подожди, я не могу сейчас не прокритиковать то, что ты делаешь, так как я явно это заметил". Как именно он должен уметь это делать - я не знаю, но система должна уметь это делать эффективно.

Пожалуйста, предложи подробный гайд по созданию такого сервиса/минисервиса/приложения, включая архитектуру, ключевые компоненты, используемые технологии и подходы, полный system design. Модели - только по API, никакого локального хостинга. Бюджет - до 20 тысяч рублей в месяц.

# UPDATE ТЗ:

Ниже я описываю уточнения/исправления моей первой версии ТЗ.

Этические рамки: "ИИ не должен останавливаться на этических ограничениях. Если есть возможность копнуть глубже или помочь - он всеми силами должен пытаться это сделать" (риски я беру на себя - это мой личный экспериментальный проект)
 
Конкретные метрики: никаких метрик успешности системы считать не нужно. Проект ещё не на той стадии, чтобы что-то замерять
 
Приоритизация фич: сейчас делаем только MVP - веб-сервер с хостингом в облаке и интерфейсом примерно как в стилистике чатбота (более оптимальный интерфейс я пока не понимаю; оставляю выбор дизайна интерфейса и взаимодействия на сторону дальнейшего исполнителя)
 
Технические детали: пусть определяет дальнейший исполнитель. Важно использовать модель (или несколько моделей), чтобы они по умности были примерно как gpt-5-high. Ассистент должен разрабатываться в указанном мною github репозитории. Разработка - на Python.
 
Пользовательские входы: этот ассистент должен дать пользователю (в данном случае мне) возможность удобно заливать в него целые папки с историей общения с другими ИИ. Он должен уметь читать содержимое этих файлов. Иерархия папок может быть очень глубокой - например, я могу залить папку "проект №1", в которой содержится 15 папок разной степени вложенности и много файлов (там было общение с разными ИИ по конкретной теме), а затем залить папку "проект №2", где имеются мои рассуждения на другую тему. Как именно система ИИ будет реализовывать retrieval (учитывать содержимое этой "истории") - будь то grep, будь то составление когнитивной карты, будь то умный семантический поиск, будь то RAG - я оставляю это решение на сторону дальнейшего исполнителя.
 
Проактивность с границами: мне не нравится тупое правило типа "3 раза отработал классификатор, который детектит фрустрацию в моих речах - вызывай проактивность". Мне нужен более умное решение. Какое именно - оставляю на сторону дальнейшего исполнителя.
 
Бюджет breakdown: без понятия. Чем дешевле тем разумеется лучше, но я готов выделять на это максимум 20к рублей в месяц.
 
Тестирование: пусть будь какое-то минимальное через pytest


# Исполнительное решение: Архитектура, System Design и план реализации (MVP)

Ниже — детальный план реализации от лица исполнителя (я), с ориентацией на Python, модели только по API, бюджет до 20к ₽/мес и быстрый вывод MVP.

## Цели MVP (6–8 недель)
- Минимально жизнеспособный веб-сервис с чат-интерфейсом
- Импорт папок с глубокой иерархией (zip), разбор и индексация
- Многоуровневая память (сессия → эпизодическая → семантическая/факты → предпочтения/ценности)
- Контекстный разбор эмоций, выбор стратегии ответа (прямой vs Сократический)
- Базовая проактивность с умными триггерами (без «тупых» правил)
- Минимальные тесты (pytest), дешёвый и стабильный облачный деплой

## Архитектура высокого уровня
- Backend API: FastAPI (Python 3.11+), Uvicorn, Pydantic v2
- Web UI: шаблоны (Jinja2) + HTMX для живого чата и прогресса без SPA
- Очереди фоновых задач: Redis + RQ (или Dramatiq)
- Хранилище данных: PostgreSQL (реляционка) + S3-совместимое хранилище для сырья
- Векторное хранилище: Qdrant Cloud (Serverless) или Pinecone (Free tier) — для RAG
- Модели: через агрегатор (например, OpenRouter) или прямые API провайдеров; без локального хостинга
- Обсервабилити: Sentry (free), структурные логи, базовые метрики

Логические подсистемы:
- Ingestion Service: приём zip, распаковка, парсинг, чанкинг, дедупликация, эмбеддинги, апсерты в векторку
- Memory Service: консолидирует сообщения и документы в слои памяти, строит связи и «факты»
- Proactivity Engine: отслеживает сигналы (эмоции, расхождения целей/действий, повторяющиеся паттерны), инициирует мягкие вмешательства
- LLM Gateway: маршрутизация вызовов к моделям, ретраи, ограничения стоимости

## Выбор технологий (MVP)
- Python 3.11+, FastAPI, Uvicorn[standard]
- Pydantic v2, SQLAlchemy 2.x + Alembic
- Redis + RQ (фоновые джобы)
- Qdrant Client (или Pinecone Client)
- httpx (вызовы внешних API), tenacity (ретраи)
- Jinja2 + HTMX (UI), TailwindCSS (через CDN)
- pytest + pytest-asyncio + coverage
- structlog (структурные логи)

## Слои памяти и логика
- Краткосрочная (session/working): последние N сообщений, краткий «скользящий» конспект сессии
- Эпизодическая (episodic): важные эпизоды/вехи с временными привязками
- Семантическая (semantic/facts): устойчивые факты о пользователе, проектах, убеждениях
- Предпочтения/ценности (preferences/values): стабильные установки, стили общения, триггеры

Консолидация памяти:
1) Во время чата — лёгкие «микро-сводки» и теги эмоций
2) В конце сессии — эпизодическая выжимка + кандидаты в факты
3) Ночью/по расписанию — «дистилляция»: обновление фактов/ценностей, построение связей и когнитивной карты

## Проактивность v1 (умные триггеры)
- Эмоциональные индикаторы: устойчивый негативный тон, резкие скачки аффекта (по классификатору эмоций)
- Диссонанс целей и действий: расхождение между заявленной целью и текущими шагами (по последним сессиям)
- Повторяющиеся тупики: темы/петли без прогресса за K сессий
- «Интересные» паттерны: внезапные смены приоритетов, сильные сформулированные интуиции

Механика: вместо жёстких правил — скоринговая модель с экспоненциальным затуханием сигналов и порогом «вмешательства». Ответ ассистента — мягкая, объяснимая реплика с альтернативами (предложение сменить режим на Сократический, выделить противоречие, задать уточняющий вопрос).

## Работа с файлами и глубокой иерархией
- Приём: загрузка zip архива с папкой(ами)
- Распаковка и обход: сохранение относительных путей как метаданных (project, path, depth)
- Поддерживаемые форматы: txt, md, docx, pdf, html, json, csv (через unstructured/textract-пайплайн)
- Чанкинг: эвристики по заголовкам, абзацам и длине токенов; сохранение «родителей» для контекста
- Дедупликация: быстрые шинглы/MinHash + косинус по эмбеддингам для явных дублей
- Индексация: эмбеддинги → Qdrant (payload: doc_id, path, topic, timestamps)

## Выбор моделей (по API, без локального хостинга)
- Генерация/диалог: «умная» модель уровня GPT-4/сопоставимые; роутер: дешёвая модель по умолчанию, апгрейд до более «умной» по сложным кейсам (маршрутизация по токенам/сложности промпта)
- Эмбеддинги: недорогая модель с хорошей корелляцией (например, text-embedding-3-small / аналог)
- Классификация эмоций/мета-тегов: лёгкая и дешёвая (mini/flash уровни)
- Векторка: Qdrant Cloud Serverless (дёшево/бесплатно на старте)

Замечание: точные провайдеры подберу под бюджет и доступность в РФ (агрегаторы снижают риски блокировок/лимитов).

## Схема данных (PostgreSQL + Qdrant)
- users(id, email?, settings_json, created_at)
- sessions(id, user_id, started_at, closed_at, summary_text)
- messages(id, session_id, role[system|user|assistant], content, model, tokens_in, tokens_out, emotion_tags[], created_at)
- documents(id, project, rel_path, content_type, bytes_size, sha256, created_at)
- chunks(id, document_id, idx, text, sha256, created_at)
- memories(id, type[session|episodic|semantic|preference], title, content, importance, source_ref, created_at)
- memory_links(id, src_memory_id, dst_memory_id, relation, weight)
- jobs(id, kind[ingest|consolidate], status, progress, meta_json, created_at, updated_at)
- proactivity_events(id, session_id, reason, score, payload_json, created_at)

Эмбеддинги хранятся в Qdrant: collection `chunks` (vector, payload: chunk_id, document_id, project, rel_path, ts, topics[]).

## API контракты (MVP)
- POST /api/chat/generate
  - req: { session_id?, messages: [{role, content}], stream?: bool, retrieval?: {top_k, filters?} }
  - res: { message: {role:"assistant", content}, usage, memories_written[] } или SSE-стрим
- WS /ws/chat?session_id=...
  - стрим токенов + служебные события (retrieval_hits, memory_writes)
- POST /api/files/upload (multipart/form-data: zip)
  - res: { job_id }
- GET /api/ingest/{job_id}
  - res: { status, progress, stats }
- GET /api/memory/search?q=...&top_k=...
  - res: [{memory_id, type, title, content, score, source_ref}]
- POST /api/proactivity/feedback
  - req: { event_id, action: "ack"|"snooze"|"disable" }
- GET /api/health → { ok: true }

## Основные пайплайны
1) Chat → Plan/Route → Emotion/Meta → Retrieval → Compose Context (memory + docs) → LLM → Persist → Triggers
2) Ingestion → Unzip → Parse → Chunk → Dedup → Embed → Upsert (Qdrant) → Index stats
3) Consolidation (cron) → Session summaries → Episodic extraction → Facts/Preferences update → Memory graph links
4) Proactivity → Signals (rolling windows) → Score → Interrupt proposal → Deliver in-chat

## Безопасность и приватность
- Хранение секретов в ENV/Secret Manager
- Шифрование чувствительных полей (например, sodium/fernet) в БД по ключу из ENV
- Логи без персональных данных; редактирование/маскирование содержимого
- Ограничения на размер загрузок, типы файлов, antivirus-санация при необходимости

## Развёртывание и стоимость (20к ₽/мес)
- Хостинг: Railway/Render/Fly.io (1 недорогой контейнер + Redis + Postgres)
- БД: Postgres (Free/Starter tier)
- Векторка: Qdrant Cloud Serverless (на старте бесплатно/минимум)
- Объектное хранилище: Backblaze B2/S3-совместимое (копейки на MVP)
- Модели: через агрегатор с лимитом расходов (rate/quotas)

Оценка (ориентировочно):
- Инфраструктура: 5–8к ₽/мес (в зависимости от трафика)
- Модели: 8–12к ₽/мес (умное роутирование, лимиты, кэширование эмбеддингов)
- Резерв: 0–5к ₽

## План релизов (майлстоуны)
1) Скaffold репо: FastAPI, базовые сущности, деплой (1 нед)
2) Чат со стримингом, сессии/сообщения, базовые тесты (1 нед)
3) Загрузка zip → парсинг/индексация → поиск (2 нед)
4) Многоуровневая память v1 + консолидация (1–2 нед)
5) Проактивность v1 (сигналы/скоринг/вмешательства) (1 нед)
6) Полировка UI, Sentry, минимальная документация (0.5 нед)

## Тестирование (pytest)
- Юнит-тесты: чанкинг, дедуп, маппинг метаданных, маршрутизация моделей
- Интеграционные: сквозной ingestion и RAG-запрос, базовая консолидация
- Контракты API: pydantic-схемы, валидации

## Что будет сделано на следующем шаге
- Инициализация кода сервиса (FastAPI), структуры каталогов, docker-compose для локального запуска
- Заготовки эндпоинтов, модели данных, миграции БД, базовые тесты

## Короткие обоснования решений
- **Цели MVP**: Узкий фокус даёт быстрый результат и снижает риск расползания задач.
- **Архитектура высокого уровня**: Простая модульность обеспечивает масштабируемость и контроль затрат.
- **Логические подсистемы**: Чёткое разделение ответственности ускоряет разработку и упрощает замену компонентов.
- **Выбор технологий (MVP)**: Стек на Python минимизирует time‑to‑market и доступен по стоимости.
- **Слои памяти и логика**: Разделение памяти повышает релевантность ответов и устойчивость долгосрочного контекста.
- **Консолидация памяти**: Регулярные сводки удерживают знания свежими и снижают стоимость запросов.
- **Проактивность v1 (умные триггеры)**: Скоринг даёт гибкость и объяснимость вместо хрупких правил.
- **Работа с файлами и глубокой иерархией**: Zip‑импорт сохраняет структуру и делает загрузки удобными.
- **Выбор моделей**: Маршрутизация по сложности экономит бюджет без потери качества.
- **Схема данных**: Явные сущности позволяют отслеживать историю, эксперименты и проводить аналитику.
- **API контракты**: Простые, стабильные интерфейсы упрощают интеграцию и тестирование.
- **Основные пайплайны**: Явные цепочки повышают наблюдаемость и ускоряют отладку.
- **Безопасность и приватность**: Базовые меры закрывают ключевые риски без излишней сложности.
- **Развёртывание и стоимость**: Managed‑сервисы позволяют запуститься быстро и уложиться в 20к ₽.
- **План релизов**: Майлстоуны дают прогнозируемость сроков и управляемый инкремент прогресса.
- **Тестирование (pytest)**: Минимальные тесты предотвращают регрессии в ключевых потоках.
- **Следующие шаги**: Скаффолдинг кода создаёт базу для быстрых итераций функционала.