# compass

MVP сервис на FastAPI для рефлексивного ассистента.

Важно: сейчас чат отвечает «заглушкой» (без реальной LLM). Индексация документов и гибридный поиск выполняются локально (BM25 + плотные эмбеддинги, HyDE, RRF, MMR) и работают даже без внешних сервисов — в этом случае используется детерминированный хэш-фолбэк. Если добавить ключи для Embeddings или указать локальную модель, качество dense-поиска заметно возрастёт.

## Что понадобится
- Установленный Python 3.11+
- Git
- Терминал (Windows: PowerShell или Git Bash)

## Где брать и куда платить (ключи)
- Embeddings (опционально, но заметно повышает качество):
  - Вариант A: [OpenRouter](https://openrouter.ai) — зарегистрируйтесь, пополните баланс/привяжите карту, создайте API‑ключ.
  - Вариант B: [OpenAI](https://platform.openai.com) — включите оплату (billing), создайте API‑ключ.
  - Пример модели: `text-embedding-3-small` (OpenAI) или аналог у провайдера в формате OpenAI API.
  - Если ключей нет, сервис использует лёгкий хэш-эмбеддинг и продолжает работать.
- Локальная модель вместо API (альтернатива ключам): укажите `LOCAL_EMBEDDING_MODEL=intfloat/multilingual-e5-base` (или другой чекпоинт `sentence-transformers`) — модель загрузится при старте.

Платить нужно только внешним провайдерам (если вы используете их API). Без ключей всё запускается, но качество поиска будет базовым.

## Запуск — пошагово (Windows/macOS/Linux)
1) Клонируйте репозиторий и зайдите в папку
```
git clone <URL_ВАШЕГО_РЕПО>
cd compass
```

2) Создайте виртуальное окружение и активируйте его
- Windows (PowerShell):
```
python -m venv .venv
Set-ExecutionPolicy -Scope CurrentUser RemoteSigned -Force
.venv\Scripts\Activate.ps1
```
- macOS/Linux:
```
python -m venv .venv
source .venv/bin/activate
```

3) Установите зависимости
```
pip install -r requirements.txt
```

4) (Опционально, но рекомендовано) Создайте файл `.env` в корне проекта со своими переменными
Пример содержимого:
```
# БД (по умолчанию — SQLite файл в ./data)
DATABASE_URL=sqlite:///./data/compass.db

# Embeddings в стиле OpenAI API (для плотного поиска)
EMBEDDINGS_API_BASE=https://api.openai.com/v1
EMBEDDINGS_API_KEY=sk-...ваш_ключ...
EMBEDDINGS_MODEL=text-embedding-3-small

# Локальная модель вместо внешнего API (опционально)
# LOCAL_EMBEDDING_MODEL=intfloat/multilingual-e5-base

# Настройки гибридного поиска
RETRIEVAL_INDEX_PATH=./data/indexes
RETRIEVAL_DENSE_TOP_K=12
RETRIEVAL_SPARSE_TOP_K=24
RETRIEVAL_ENABLED=true

# LLM (OpenAI/OpenRouter совместимый Chat Completions)
LLM_API_BASE=https://api.openai.com/v1
LLM_API_KEY=sk-...ваш_ключ...
LLM_MODEL_FAST=gpt-3.5-turbo
LLM_MODEL_SMART=gpt-4o
ETHICS_MODE=experimental
```

5) Запустите сервер разработки
```
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

6) Проверьте, что сервис жив
```
GET http://localhost:8000/api/health
```
Должно вернуть: `{ "ok": true }`

## Как пользоваться (примеры)
- Веб‑интерфейс чата: открой в браузере http://localhost:8000/chat

- HTTP чат (пока заглушка ответа):
```
curl -s -X POST http://localhost:8000/api/chat/generate \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "Привет"}
    ]
  }'
```

- Загрузка zip с данными (любой набор папок/файлов внутри):
```
curl -s -X POST http://localhost:8000/api/files/upload \
  -F zip_file=@/полный/путь/к/архиву.zip
```
Ответ содержит `job_id`. Статус обработки:
```
curl -s http://localhost:8000/api/ingest/<job_id>
```
После загрузки ZIP выполняется токен-бейзная нарезка (500–1000 токенов), MinHash-дедупликация и обновление локальных индексов (BM25 + dense). Повторный аплоад с тем же `job_id` обновит версии чанков и переиндексирует их.
Раз в месяц (1 число, 02:00) планировщик пересобирает dense/BM25 индексы и заново считает эмбеддинги для накопленных чанков. Команду можно вызвать вручную: `python -m app.services.index_maintenance` (или импортировать и вызвать `rebuild_all_indexes`).

- WebSocket стриминг чата (стаб):
Установите любой WS‑клиент (например, [`websocat`](https://github.com/vi/websocat) или `wscat`). Пример с websocat:
```
websocat ws://localhost:8000/ws/chat
Привет
```
Вы увидите поток токенов и в конце `[DONE]`.

## «Инструкция для тупых»: от нуля до работы с iPhone

Ниже — максимально подробный сценарий без предположений, что вы что-то знаете заранее. Повторяйте шаги по порядку.

### Шаг 0. Что у вас должно быть под рукой
1. **Компьютер** (Windows 10/11, macOS или Linux) с выходом в интернет. На нём вы будете запускать сервер.
2. **iPhone**, подключённый к той же Wi‑Fi сети, что и компьютер. Это нужно, чтобы телефон увидел локальный сервер.
3. Желательно минимум 10 ГБ свободного места на компьютере (под Python, виртуальное окружение и индексы).

### Шаг 1. Поставьте инструменты на компьютер
1. Скачайте и установите **Python 3.11** с сайта [python.org](https://www.python.org/downloads/). При установке отметьте галочку «Add Python to PATH» (Windows) или следуйте мастеру (macOS). На Linux обычно Python уже есть.
2. Установите **Git**: [git-scm.com/downloads](https://git-scm.com/downloads). На macOS можно через Xcode Command Line Tools (`xcode-select --install`).
3. Откройте терминал:
   - Windows: «Пуск» → «PowerShell».
   - macOS: Spotlight → «Terminal».
   - Linux: любой терминал.

### Шаг 2. Скачайте и подготовьте проект
1. В терминале выполните:
   ```
   git clone <URL_ВАШЕГО_РЕПО>
   cd compass
   ```
   Замените `<URL_ВАШЕГО_РЕПО>` на адрес репозитория (например, `https://github.com/username/compass.git`).
2. Создайте виртуальное окружение:
   ```
   python -m venv .venv
   ```
3. Активируйте окружение:
   - Windows PowerShell: `.venv\Scripts\Activate.ps1`
   - macOS/Linux: `source .venv/bin/activate`
4. Установите зависимости:
   ```
   pip install -r requirements.txt
   ```

### Шаг 3. Настройте переменные окружения
1. Создайте файл `.env` в корне проекта. Самый простой способ — скопировать пример ниже:
   ```
   DATABASE_URL=sqlite:///./data/compass.db
   RETRIEVAL_ENABLED=true
   RETRIEVAL_INDEX_PATH=./data/indexes

   # Если ключей для embeddings нет — оставьте строки ниже закомментированными.
   # EMBEDDINGS_API_BASE=https://api.openai.com/v1
   # EMBEDDINGS_API_KEY=sk-...
   # EMBEDDINGS_MODEL=text-embedding-3-small

   # Можно указать локальную модель вместо API (скачается при первом запуске):
   # LOCAL_EMBEDDING_MODEL=intfloat/multilingual-e5-base

   # Настройки LLM (по умолчанию заглушка, но можно подключить реальную модель по API):
   # LLM_API_BASE=https://api.openai.com/v1
   # LLM_API_KEY=sk-...
   # LLM_MODEL_FAST=gpt-3.5-turbo
   # LLM_MODEL_SMART=gpt-4o
   ```
2. Если вы хотите улучшить качество dense-поиска, получите API-ключ у OpenAI/OpenRouter и раскомментируйте соответствующие строки. Если ключей нет, ничего страшного — включится встроенный хэш-фолбэк.

### Шаг 4. Запустите сервер на компьютере
1. В том же активированном виртуальном окружении выполните:
   ```
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   ```
   - Ключ `--host 0.0.0.0` делает сервер доступным не только с компьютера, но и с других устройств в сети (iPhone).
   - Если Windows Firewall спросит разрешение — нажмите «Allow»/«Разрешить».
2. Убедитесь, что всё поднялось: в браузере компьютера откройте `http://localhost:8000/api/health`. Должен вернуться JSON `{ "ok": true }`.

### Шаг 5. Добавьте свою базу знаний (опционально)
1. Подготовьте ZIP-архив с файлами, которые ассистент должен помнить.
2. В новом терминале (окружение можно не выключать) выполните:
   ```
   curl -s -X POST http://localhost:8000/api/files/upload \
     -F zip_file=@/полный/путь/к/архиву.zip
   ```
3. Запомните `job_id` из ответа. Проверьте статус:
   ```
   curl -s http://localhost:8000/api/ingest/<job_id>
   ```
4. Подождите, пока статус станет `completed`. После этого индексы обновлены, и ассистент будет использовать ваши данные.

### Шаг 6. Узнайте IP компьютера
1. Компьютер и iPhone должны быть в одной сети (обычно домашний Wi‑Fi).
2. Чтобы iPhone подключился, выясните локальный IP компьютера:
   - Windows: в PowerShell `ipconfig` → в разделе текущей сети найдите `IPv4 Address`, например `192.168.1.23`.
   - macOS/Linux: команда `ifconfig` или `ip addr` → найдите адрес вида `192.168.x.y` (не `127.0.0.1`).
3. Запишите этот IP — он понадобится на телефоне.

### Шаг 7. Подключитесь с iPhone
1. На iPhone откройте Safari (или другой браузер).
2. В адресную строку введите `http://<IP_КОМПЬЮТЕРА>:8000/chat`. Пример: `http://192.168.1.23:8000/chat`.
3. Должен открыться веб-интерфейс ассистента. Если страница не грузится:
   - Проверьте, что сервер на компьютере всё ещё работает (в терминале должен идти лог `Uvicorn running on ...`).
   - Убедитесь, что iPhone в той же сети и IP введён без опечаток.
   - Если используется VPN или корпоративный роутер, который изолирует устройства, подключите телефон по USB и включите «Персональный доступ к интернету» (macOS) или настройте проброс через [ngrok](https://ngrok.com) / [Cloudflare Tunnel](https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/) (необязательно, но помогает при жёсткой сегментации сети).

### Шаг 8. Общайтесь и пользуйтесь контекстом
1. В веб-интерфейсе с iPhone вводите сообщения — чат отвечает, опираясь на:
   - Ваш текущий запрос.
   - Диалоговую историю (контекст сессии).
   - Загрузки из базы знаний (чанки, которые вы добавили ZIP-архивом).
2. Вся обработка идёт на вашем компьютере. iPhone — только интерфейс.
3. Чтобы ассистент знал больше, загружайте новые ZIP-файлы. Повторная загрузка перезапишет данные для того же `job_id`.

### Шаг 9. Когда закончите
1. На компьютере остановите сервер сочетанием клавиш `Ctrl+C` в окне, где запущен uvicorn.
2. При следующем запуске повторите шаг 4 (активируйте окружение и запустите сервер).

### Что делать, если что-то не получилось
- **Не открывается страница на iPhone** — проверьте IP, брандмауэр Windows, VPN/антивирусы. Попробуйте временно отключить «Общий доступ к защите» или добавить правило для порта 8000.
- **Ошибка при загрузке ZIP** — убедитесь, что архив не пустой и его размер не превышает лимит (см. логи сервера). Также проверьте, что папка `data/indexes` существует и доступна для записи.
- **Ассистент не вспоминает ваши файлы** — посмотрите статус `job_id`, возможно ingestion ещё не закончился. В логах должны появиться сообщения о построении индексов.
- **Хотите доступ из другой сети (мобильный интернет)** — используйте туннелирование (ngrok, Cloudflare Tunnel) или задействуйте облачный хостинг из раздела «Деплой».

Следуя этому чек-листу, вы с нуля запускаете приложение на компьютере и используете его из браузера iPhone, получая ответы с учётом собственной базы знаний и истории диалога.

## Где данные
- База данных по умолчанию: `./data/compass.db` (SQLite)
- Загрузки: `./data/uploads/`
- Временные файлы ingestion/чанки: `./data/tmp/` (в т.ч. `chunks.json` для каждой задачи)
- Локальные поисковые индексы: `./data/indexes/` (dense.json, sparse.json, chunks.json)

## Тесты
```
pytest -q
```

## Docker (опционально)
Собрать и запустить локально:
```
docker build -t compass .
docker run --rm -p 8000:8000 --env-file .env compass
```

## Типовые проблемы и решения
- «403/401 при индексации» — проверьте `EMBEDDINGS_API_KEY` и `EMBEDDINGS_API_BASE`.
- «Нет индексации» — убедитесь, что `data/indexes` доступна для записи. Для лучшего качества задайте EMBEDDINGS_* или LOCAL_EMBEDDING_MODEL.
- «Не активируется venv на Windows» — запускайте PowerShell от имени администратора или разрешите выполнение скриптов: `Set-ExecutionPolicy -Scope CurrentUser RemoteSigned`.
- «Падает парсинг PDF/HTML/DOCX» — убедитесь, что установлены зависимости (см. requirements), и файлы не защищены.

## Деплой в облако (Render / Railway)
### Render (с Docker)
1. Загрузите репозиторий в GitHub
2. На `render.com` создайте Web Service → выбор репо → Render прочитает `render.yaml`
3. Добавьте переменные окружения (секция Environment) из `.env`
4. Деплой стартует автоматически, проверка: `GET https://<your-app>.onrender.com/api/health`

### Railway (с Procfile)
1. Загрузите репозиторий в GitHub
2. На `railway.app` создайте проект, подключите репозиторий
3. Railway обнаружит `Procfile` и запустит веб процесс
4. Добавьте переменные окружения из `.env`

## Что готово сейчас и чего ждать дальше
- Готово: каркас FastAPI, REST/WS чат (стабы), загрузка zip, токен-бейзный ingestion + MinHash, локальные индексы BM25+dense с HyDE/RRF/MMR, БД для сессий/сообщений.
- В планах: подключение реальной LLM по API, улучшение RAG-контекста, многоуровневая память и проактивность.

